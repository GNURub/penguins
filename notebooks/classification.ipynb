{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# Eliminamos los rows con alguna columna vacia\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division del dataset en train (80%) y test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['species'] =  LabelEncoder().fit_transform(df['species']) # Adelie -> 0, Chinstrap -> 1, Gentoo -> 2\n",
    "\n",
    "X = df.drop(columns=['species'])\n",
    "y = df['species']\n",
    "\n",
    "train_data_x, test_data_x, train_data_y, test_data_y = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Variables categoricas\n",
    "categorical = ['island', 'sex']\n",
    "\n",
    "# Transformaci√≥n one-hot\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "x_train_cat = vectorizer.fit_transform(train_data_x[categorical].to_dict(orient='records'))\n",
    "x_test_cat = vectorizer.transform(test_data_x[categorical].to_dict(orient='records'))\n",
    "\n",
    "# Variables numericas\n",
    "numerical = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "\n",
    "# Escalado de las variables numericas\n",
    "scaler = StandardScaler()\n",
    "x_train_num = scaler.fit_transform(train_data_x[numerical])\n",
    "x_test_num = scaler.transform(test_data_x[numerical])\n",
    "\n",
    "# Usamos (https://iedib.net/avirtual/mod/forum/discuss.php?d=59418) np.hstack() para juntarlos los ndarrays\n",
    "x_train = np.hstack((x_train_cat, x_train_num))\n",
    "x_test = np.hstack((x_test_cat, x_test_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Entrenamiento https://www.kaggle.com/code/paulgreber/logistic-regression-with-palmer-s-penguins\n",
    "lr = LogisticRegression().fit(x_train, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        28\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        67\n",
      "   macro avg       1.00      1.00      1.00        67\n",
      "weighted avg       1.00      1.00      1.00        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Usamos los datos de prueba para realizar la prediccion\n",
    "prediction = lr.predict(x_test)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_data_y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear',C=1.0, random_state=1, probability=True).fit(x_train, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        28\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        67\n",
      "   macro avg       1.00      1.00      1.00        67\n",
      "weighted avg       1.00      1.00      1.00        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usamos los datos de prueba para realizar la prediccion\n",
    "prediction = svm.predict(x_test)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_data_y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decission Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='gini',max_depth=4,\n",
    "                                    random_state=4).fit(x_train, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        28\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.96      0.98      0.97        67\n",
      "weighted avg       0.97      0.97      0.97        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usamos los datos de prueba para realizar la prediccion\n",
    "prediction = dt.predict(x_test)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_data_y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, p=2, metric='minkowski').fit(x_train, train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        28\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        67\n",
      "   macro avg       1.00      1.00      1.00        67\n",
      "weighted avg       1.00      1.00      1.00        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usamos los datos de prueba para realizar la prediccion\n",
    "prediction = knn.predict(x_test)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_data_y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialitzaci√≥n de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# A m√©s de cada model, hem de serialitzar el StandardScaler (sc)\n",
    "#  per poder aplicar la mateixa transformaci√≥ a les dades d'entrada de les prediccions\n",
    "\n",
    "with open('../models/lr.pck', 'wb') as f:\n",
    "    pickle.dump((vectorizer, scaler, lr), f)\n",
    "\n",
    "with open('../models/svm.pck', 'wb') as f:\n",
    "    pickle.dump((vectorizer, scaler, svm), f)\n",
    "\n",
    "with open('../models/dt.pck', 'wb') as f:\n",
    "    pickle.dump((vectorizer, scaler, dt), f)\n",
    "\n",
    "with open('../models/knn.pck', 'wb') as f:\n",
    "    pickle.dump((vectorizer, scaler, knn), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penguins-x356dO5--py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
